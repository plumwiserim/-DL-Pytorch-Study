# 03. 선형 회귀(Linear Regression)
# 03-06. 미니 배치와 데이터 로드(Mini Batch and Data Load)

import torch 
import torch.nn

# 1. 미니 배치와 배치 크기(Mini Batch and Batch Size)
# 데이터 
x_train = torch.FloatTensor([[73, 80, 75],
                             [93, 88, 93],
                             [89, 91, 90],
                             [96, 98, 100],
                             [73, 66, 70]])
y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])

# 위 데이터의 샘플의 수는 5개입니다. 
# 전체 데이터에 대해서 경사 하강법을 수행하여 학습할 수도 있지만 
# 만약 데이터가 수십만개 이상이라면 전체 데이터에서 경사 하강법을 수행하는 것은 매우 느릴 뿐만 아니라 많은 계산량이 필요하다. 
# 어쩌면 메모리의 한계로 계산이 불가능한 경우도 있을 수 있다. 
# 그렇기 때문에 전체 데이터를 더 작은 단위로 나누어서 해당 단위로 학습하는 개념, 즉 미니 배치가 나오게 되었다. 

# 미니 배치 학습을 하게 되면 미니 배치만큼만 가져가서 미니 배치에 대한 비용(cost)를 계산하고, 경사하강법을 수행한다. 
# 그리고 다음 미니 배치를 가져가서 경사 하강법을 수행하고 반복한다. 
# 이렇게 전체 데이터에 대한 학습이 끝나면 1 epoch가 끝나게 된다. 

# 배치 크기는 보통 2의 제곱수를 사용합니다. 
# 그 이유는 CPU와 GPU의 메모리가 2의 배수이므로 배치 크기가 2의 제곱수일 경우에 데이터 송수신의 효율을 높일 수 있다고 한다. 

